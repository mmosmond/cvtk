{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Castro et al. (2019) Data Processing and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "from functools import reduce\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvtk.cvtk import TemporalFreqs, TiledTemporalFreqs\n",
    "from cvtk.cov import stack_temporal_covariances\n",
    "import cvtk.variant_files as vf\n",
    "from cvtk.gintervals import GenomicIntervals\n",
    "from cvtk.pca import FreqPCA\n",
    "from cvtk.plots import rep_plot_pca, correction_diagnostic_plot\n",
    "from cvtk.utils import integerize\n",
    "from cvtk.utils import extract_empirical_nulls_diagonals, extract_temporal_cov_diagonals\n",
    "from cvtk.cov import stack_replicate_covariances, stack_temporal_covs_by_group\n",
    "from cvtk.variant_files import VCFFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "mpl.rcParams['figure.figsize'] = (8.0, 4.0)\n",
    "mpl.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varianta Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in VCF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file '../data/castro_et_al_2019/beagle_genMap.all.impute.vcf.gz'...\n",
      "file '../data/castro_et_al_2019/beagle_genMap.all.impute.vcf.gz' loaded.\n",
      "total time to load VCF file: 9.34765721956889 mins.\n"
     ]
    }
   ],
   "source": [
    "vcf = VCFFile('../data/castro_et_al_2019/beagle_genMap.all.impute.vcf.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in variant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the raw `.frq` files, which contain all sites whether segregating in the sample, or not. This makes a row-wise join easy. \n",
    "\n",
    "The following list is our design for this experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "design = [('Ctrl', 0), ('Ctrl', 17), ('LS1', 0), ('LS1', 17), ('LS2', 0), ('LS2', 17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading frequency matrix from cached pickle file...\n"
     ]
    }
   ],
   "source": [
    "CACHED_FREQS = '../data/castro_et_al_2019/castro_et_al_2019_frequencies.pkl'\n",
    "CACHED_POS = '../data/castro_et_al_2019/castro_et_al_2019_loci.pkl'\n",
    "if not os.path.exists(CACHED_FREQS):\n",
    "    print(\"processing frequency matrix from raw data...\")\n",
    "    frq_files = glob.glob('../data/castro_et_al_2019/*frq')\n",
    "    all_data = dict()\n",
    "    all_metadata = []\n",
    "\n",
    "    first = True\n",
    "    for frq_file in frq_files:\n",
    "        m = re.match(r'beagle_genMap\\.all\\.impute\\.(?P<line>\\w+)_F(?P<gen>\\w+).frq', os.path.basename(frq_file))\n",
    "        metadata = m.groupdict()\n",
    "        all_metadata.append(metadata)\n",
    "        d = pd.read_csv(frq_file, delimiter='\\t', index_col=False)\n",
    "        d.columns = ['chrom', 'pos', 'nalleles', 'nchr', 'freq']\n",
    "        # assert the data has the exact same loci in all cases\n",
    "        if first:\n",
    "            loci = set([(chrom, pos) for chrom, pos in zip(d['chrom'], d['pos'])])\n",
    "        else:\n",
    "            assert(loci == set([(chrom, pos) for chrom, pos in zip(d['chrom'], d['pos'])]))\n",
    "        all_data[(metadata['line'], int(metadata['gen']))] = d\n",
    "    \n",
    "    # combine all frequencies into a matrix\n",
    "    total_freq_mat = np.array([all_data[key]['freq'].values for key in design])\n",
    "    \n",
    "    # filter out non-segregating sites\n",
    "    fixed_sites = np.all((total_freq_mat == 0) | (total_freq_mat == 1), axis=0)\n",
    "    freq_mat = total_freq_mat[:, ~fixed_sites]\n",
    "    seg_indices = set(list(np.argwhere(~fixed_sites).ravel()))\n",
    "    \n",
    "    # cache the frequency matrix\n",
    "    print(\"saving frequency matrix cached pickle file...\")\n",
    "    with open(CACHED_FREQS, 'wb') as f:\n",
    "        pickle.dump(freq_mat, f)\n",
    "        \n",
    "    print(\"rebuilding loci GenomicIntervals...\")\n",
    "    gi = GenomicIntervals()\n",
    "    for i, row in enumerate(all_data[('Ctrl', 0)].itertuples(index=False)):\n",
    "        if i not in seg_indices:\n",
    "            # We only keep segregating sites, which are filtered out once the frequency\n",
    "            # matrix is parsed. We don't include loci that aren't in the freq matrix.\n",
    "            continue\n",
    "        chrom, pos = row[0:2]\n",
    "        gi.append(chrom, int(pos))\n",
    "    print(\"caching loci GenomicIntervals...\")\n",
    "    gi.dump(CACHED_POS)\n",
    "else:\n",
    "    # load the existing cached matrix\n",
    "    print(\"loading frequency matrix from cached pickle file...\")\n",
    "    with open(CACHED_FREQS, 'rb') as f:\n",
    "        freq_mat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to load loci file\n",
    "if not os.path.exists(CACHED_POS):\n",
    "    raise ValueError(\"cached loci file not found — regenerate frequency matrix and loci GenomicIntervals object.\")\n",
    "else:\n",
    "    gi = GenomicIntervals.load(CACHED_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate Data Source\n",
    "\n",
    "The directory `http://ftp.tuebingen.mpg.de/fml/ag-chan/Longshanks/` also has file http://ftp.tuebingen.mpg.de/fml/ag-chan/Longshanks/CtrlLS1LS2_F0F17.RefAlt_ReadCounts.by_chr.tar.gz which we process here.\n",
    "\n",
    "These have been pre-processed (separate chromosome files combined), and we load them in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    name = os.path.basename(file)[:-4]\n",
    "    table = pd.read_csv(file, delimiter='\\t', header=None)\n",
    "    chrom = table.loc[:, 0].values\n",
    "    pos = table.loc[:, 1].values\n",
    "    \n",
    "    m = table.loc[:, 4:].values\n",
    "    #geno_mat = np.stack((m[:, np.arange(0, m.shape[1]) % 2 == 0], m[:, np.arange(0, m.shape[1]) % 2 == 1]), axis=2)\n",
    "    m = m.astype('uint8')\n",
    "    m = np.stack((m[:, np.arange(0, m.shape[1]) % 2 == 0], m[:, np.arange(0, m.shape[1]) % 2 == 1]), axis=2)\n",
    "    \n",
    "    del table\n",
    "    \n",
    "    counts = np.nansum(m[:, :, 0], axis=1)\n",
    "    depths = np.nansum(m[:, :, 0] + m[:, :, 1], axis=1)\n",
    "    \n",
    "    del m\n",
    "    out = pd.DataFrame(dict(chrom=chrom,\n",
    "                            pos=pos,\n",
    "                            #ref=table.loc[:, 2],\n",
    "                            #alt=table.loc[:, 3],\n",
    "                            counts=counts, \n",
    "                            depths=depths))\n",
    "    \n",
    "    out.rename(columns={'counts': 'counts_' + name}, inplace=True)\n",
    "    out.rename(columns={'depths': 'depths_' + name}, inplace=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine load all the files (or use the pre-combined one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined feather file found, loading...\n"
     ]
    }
   ],
   "source": [
    "#COMBINED_CSV = '../data/castro_et_al_2019/combined_counts.csv'\n",
    "COMBINED_FEATHER = '../data/castro_et_al_2019/combined_counts.feather'\n",
    "samples = ['F17_Ctrl', 'F17_LS1', 'F17_LS2', 'P0_Ctrl', 'P0_LS1', 'P0_LS2']\n",
    "FORCE = False\n",
    "\n",
    "if FORCE or not os.path.exists(COMBINED_FEATHER):\n",
    "    print(\"no combined feather file found, generating one...\")\n",
    "    dfs = dict()\n",
    "    for sample in samples:\n",
    "        dfs[sample] = process_file(os.path.join('../data/castro_et_al_2019/chrom_depth_counts/', sample + '.tsv'))\n",
    "\n",
    "    df = reduce(lambda left, right: pd.merge(left, right, on=('chrom', 'pos'), how='outer'), dfs.values())\n",
    "    df = df.drop_duplicates().reset_index()\n",
    "    df.to_feather(COMBINED_FEATHER)\n",
    "    #df.to_csv(COMBINED_CSV, index=False)\n",
    "    \n",
    "    #del dfs, d_P0_Ctrl, d_P0_LS1, d_P0_LS2, d_F17_Ctrl, d_F17_LS1, d_F17_LS2\n",
    "else:\n",
    "    print(\"combined feather file found, loading...\")\n",
    "    df = pd.read_feather(COMBINED_FEATHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/castro_et_al_2019/chrom_depth_counts'\n",
    "files = os.listdir(DATA_DIR)\n",
    "\n",
    "FILE_REGEX = r\"(?P<gen>[^_]+)_(?P<line>[^_]+)\\.bcf_.*\"\n",
    "\n",
    "tables = defaultdict(dict)\n",
    "for file in files:\n",
    "    if file == 'i_j.bcf_mpileup.RefAlt_AD.chr1.summary':\n",
    "        # odd file that's not part of sample\n",
    "        continue\n",
    "    metadata = re.match(FILE_REGEX, file).groupdict()\n",
    "    table = pd.read_csv(os.path.join(DATA_DIR, file), delimiter='\\t', header=None)\n",
    "    counts = table.loc[:, 4:].values\n",
    "    \n",
    "    m = table.loc[:, 4:].values\n",
    "    #geno_mat = np.stack((m[:, np.arange(0, m.shape[1]) % 2 == 0], m[:, np.arange(0, m.shape[1]) % 2 == 1]), axis=2)\n",
    "    m = m.astype('uint8')\n",
    "    m = np.stack((m[:, np.arange(0, m.shape[1]) % 2 == 0], m[:, np.arange(0, m.shape[1]) % 2 == 1]), axis=2)\n",
    "    \n",
    "    chrom = table.loc[:, 0].values\n",
    "    chrom_name = table.loc[:, 0].unique()[0]\n",
    "    pos = table.loc[:, 1].values\n",
    "    ref =  table.loc[:, 2].values\n",
    "    alt =  table.loc[:, 3].values\n",
    "    sample_key = (metadata['line'], int(metadata['gen'][1:]))\n",
    "    tables[chrom_name][sample_key] = (pos, ref, alt, geno_mat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_chrs(x):\n",
    "    chr = x.replace('chr', '')\n",
    "    if chr == 'X':\n",
    "        return 1e6\n",
    "    return int(chr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-db72bb1bfd2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mchrom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0malt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgeno_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-db72bb1bfd2e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mchrom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0malt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgeno_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "pos = [tables[chr][0] for chr in sorted(tables.keys(), key=sort_chrs)]\n",
    "chrom = [chr for _ in tables[chr][0].values for chr in sorted(tables.keys(), key=sort_chrs)]\n",
    "ref = [tables[chr][1] for chr in sorted(tables.keys(), key=sort_chrs)]\n",
    "alt = [tables[chr][2] for chr in sorted(tables.keys(), key=sort_chrs)]\n",
    "geno_mat = [tables[chr][3] for chr in sorted(tables.keys(), key=sort_chrs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "autosomes = list(set(gi.intervals.keys()) - set('chrX'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_width = 1e5\n",
    "gi.infer_seqlens()\n",
    "tiles = GenomicIntervals.from_tiles(gi.seqlens, width=tile_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b01dbe383d5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTiledTemporalFreqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgintervals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/cvtk/cvtk/cvtk.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tiles, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \"\"\"\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/cvtk/cvtk/cvtk.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, freqs, samples, depths, diploids, gintervals, swap)\u001b[0m\n\u001b[1;32m     22\u001b[0m                  gintervals=None, swap=True):\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdepths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             msg = (\"frequency matrix 'freqs' must have same shape as\"\n\u001b[1;32m     26\u001b[0m                    \"matrix of sequencing depths 'depths'\")\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "d = TiledTemporalFreqs(tiles, freqs=freq_mat, samples=design, gintervals=gi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
